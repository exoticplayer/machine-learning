{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"border-box-sizing\" id=\"notebook\" tabindex=\"-1\">\n",
      "<div class=\"container\" id=\"notebook-container\">\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h1 id=\"实验二：回归模型\">实验二：回归模型<a class=\"anchor-link\" href=\"#实验二：回归模型\">¶</a></h1>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<ul>\n",
      "<li>回归是监督学习的一个重要问题，回归用于预测<strong>输入变量</strong>和<strong>输出变量</strong>之间的关系，特别是当输入变量的值发生变化时，输出变量的值也随之发生变化。</li>\n",
      "<li>回归模型是一种表示从输入变量到输出变量之间映射的函数</li>\n",
      "<li>对连续值的预测</li>\n",
      "<li>可以用合适的曲线揭示样本点随着自变量的变化关系</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h2 id=\"实验要求\">实验要求<a class=\"anchor-link\" href=\"#实验要求\">¶</a></h2><h3 id=\"截止日期：10月21日\">截止日期：10月21日<a class=\"anchor-link\" href=\"#截止日期：10月21日\">¶</a></h3><p>作业的提交格式参考之前的说明，提交到2120220594@nankai.edu.cn</p>\n",
      "<h3 id=\"基本要求\">基本要求<a class=\"anchor-link\" href=\"#基本要求\">¶</a></h3><p>将数据集winequality-white.csv按照4:1划分为训练集和测试集。</p>\n",
      "<ol>\n",
      "<li>构造线性回归模型，并采用批量梯度下降<strong>和</strong>随机梯度下降进行优化；输出训练集和测试集的均方误差（MSE），画出MSE收敛曲线。</li>\n",
      "<li>对于批量梯度下降<strong>和</strong>随机梯度下降，采用不同的学习率并进行MSE曲线展示，分析选择最佳的学习率。</li>\n",
      "</ol>\n",
      "<p>特别需要注意：</p>\n",
      "<ul>\n",
      "<li>划分数据集时尽可能保持数据分布的一致性，保持样本类别比例相似，可采用分层采样的方式。</li>\n",
      "<li>需要对数据集进行一定的预处理</li>\n",
      "</ul>\n",
      "<h3 id=\"中级要求\">中级要求<a class=\"anchor-link\" href=\"#中级要求\">¶</a></h3><p>探究回归模型在机器学习和统计学上的差异。</p>\n",
      "<ul>\n",
      "<li>回归模型在机器学习领域和统计学领域中都十分常用，而且使用方法也相似，但其实际的含义具有本质的区别。我们希望同学们从回归模型的角度更加充分地理解机器学习和统计学的区别。\n",
      "<img alt=\"image.png\" src=\"https://s2.loli.net/2022/10/04/Np71slqWZEfGwMC.png\"/></li>\n",
      "</ul>\n",
      "<h3 id=\"高级要求\">高级要求<a class=\"anchor-link\" href=\"#高级要求\">¶</a></h3><p>编程实现岭回归算法，求解训练样本的岭回归模型，平均训练误差和平均测试误差（解析法、批量梯度下降法和随机梯度下降法<strong>均可</strong>）。</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h2 id=\"线性回归\">线性回归<a class=\"anchor-link\" href=\"#线性回归\">¶</a></h2>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p>线性回归模型(Linear Regression)，因为结构简单，可解释性好，实现简单，在工程领域得到广泛应用。</p>\n",
      "<p>首先对线性函数进行简单的回顾：</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p><img alt=\"a.png\" src=\"https://s2.loli.net/2022/10/04/rdm5WLI84BNznUR.png\"/></p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"预测模型\">预测模型<a class=\"anchor-link\" href=\"#预测模型\">¶</a></h3>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p>首先，我们明确几个常用的数学符号：</p>\n",
      "<ul>\n",
      "<li>特征 (features): $x_i$, 比如房屋的面积，卧室的数量都可以是房屋的特征</li>\n",
      "<li>特征向量 (输入): $x$, 若干个特征组成的向量，代表一套房屋的所有信息。例如，$x^{(i)}_j$ 表示第 $i$ 套房的第 $j$ 个特征</li>\n",
      "<li>输出向量 $y$, $y^{(i)}$ 表示第 $i$ 个输入对应的输出</li>\n",
      "<li>假设 (hypothesis): 也称预测函数，比如一个线性的预测函数是：\n",
      "$$h_\\theta (x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+...+\\theta_nx_n=\\theta^T x$$\n",
      "上述的表达式就是<strong>回归方程 (regression equation)</strong>, $\\theta$ 就是回归系数，关系到我们预测的准确程度</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h2 id=\"一元线性回归-vs.-多元线性回归\">一元线性回归 vs. 多元线性回归<a class=\"anchor-link\" href=\"#一元线性回归-vs.-多元线性回归\">¶</a></h2>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p>假设一共有N个特征向量，对于多元线性回归有m个特征：</p>\n",
      "<ul>\n",
      "<li>数据集：<ul>\n",
      "<li>一元：$\\{(x^{(i)}, y^{(i)})\\}$  </li>\n",
      "<li>多元：$\\{(\\pmb{x}^{(i)}, y^{(i)})\\},\\\\ \\pmb{x}^{(i)}=[x^{(i)}_1, x^{(i)}_2,..., x^{(i)}_m], i=1,2,...,N$</li>\n",
      "</ul>\n",
      "</li>\n",
      "</ul>\n",
      "<ul>\n",
      "<li><p>假设：</p>\n",
      "<ul>\n",
      "<li>一元：$f(x^{(i)},\\pmb{\\theta})=\\theta_0+\\theta_1x^{(i)}$ </li>\n",
      "<li>多元：$f(\\pmb{x}^{(i)},\\pmb{\\theta})=\\theta_0+\\theta_1x^{(i)}_1+\\theta_2x^{(i)}_2 + ... +\\theta_mx^{(i)}_m $</li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><p>参数：</p>\n",
      "<ul>\n",
      "<li>一元：$\\pmb{\\theta}=[\\theta_0, \\theta_1]$</li>\n",
      "<li>多元：$\\pmb{\\theta}=[\\theta_0, \\theta_1,\\theta_2, ...,\\theta_m]$</li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><p>损失函数：</p>\n",
      "<ul>\n",
      "<li>MSE：$$Loss=\\frac{1}{N}\\sum_{i=1}^N(y^{(i)}-f(\\pmb{x}^{(i)},\\pmb{\\theta}))^2$$\n",
      "有的资料上损失函数多了个$\\frac{1}{2}$：\n",
      "$$Loss=\\frac{1}{2N}\\sum_{i=1}^N(y^{(i)}-f(\\pmb{x}^{(i)},\\pmb{\\theta}))^2$$\n",
      "目的是求导后将二次项的系数变为1，加和不加对结果理论上没有影响。</li>\n",
      "</ul>\n",
      "</li>\n",
      "<li><p>目标：损失函数最小</p>\n",
      "</li>\n",
      "<li><p>解析解：</p>\n",
      "<ul>\n",
      "<li><p>一元：分别对MSE中的$\\theta_0, \\theta_1$求偏导</p>\n",
      "</li>\n",
      "<li><p>多元：对MSE中的$\\pmb{\\theta}$求偏导\n",
      "$\\pmb{\\theta}=(\\pmb{x}^T\\pmb{x})^{-1}\\pmb{x}^Ty$</p>\n",
      "</li>\n",
      "</ul>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"优化方法\">优化方法<a class=\"anchor-link\" href=\"#优化方法\">¶</a></h3><ul>\n",
      "<li><p>直接求解析解：$\\pmb{\\theta}=(\\pmb{x}^T\\pmb{x})^{-1}\\pmb{x}^Ty$</p>\n",
      "<ul>\n",
      "<li><p>优点：不需要试错，可以直接取得最小值，比较快捷。</p>\n",
      "</li>\n",
      "<li><p>缺点：当特征过于复杂时，无法求逆。</p>\n",
      "</li>\n",
      "<li><p>适用于：小数据场景。（梯度下降相对用的更多一些）</p>\n",
      "</li>\n",
      "</ul>\n",
      "</li>\n",
      "<li>梯度下降法</li>\n",
      "<li>岭回归</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"梯度下降法\">梯度下降法<a class=\"anchor-link\" href=\"#梯度下降法\">¶</a></h3>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p><img alt=\"image.png\" src=\"https://s2.loli.net/2022/10/04/XOjpPcdCksRwQn8.png\"/></p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"学习率\">学习率<a class=\"anchor-link\" href=\"#学习率\">¶</a></h3>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p><img alt=\"image.png\" src=\"https://s2.loli.net/2022/10/04/OfuUjWLSJF3qyso.png\"/></p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"批量梯度下降\">批量梯度下降<a class=\"anchor-link\" href=\"#批量梯度下降\">¶</a></h3><p>批量梯度下降法为最小化所有训练样本的损失函数，使得最终求解的是全局的最优解。</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p><img alt=\"image.png\" src=\"https://s2.loli.net/2022/10/04/TB4DmndiJ9OVPYk.png\"/></p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p>虽然批量梯度下降能够收敛到最小值，但每调节一个$\\theta_j$都必须遍历一遍样本集，如果样本的体积m很大，那么这种算法开销巨大，但由于其向量表示，可以利用并行计算优化性能。</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"随机梯度下降\">随机梯度下降<a class=\"anchor-link\" href=\"#随机梯度下降\">¶</a></h3>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p><img alt=\"image.png\" src=\"https://s2.loli.net/2022/10/04/u6YUkgCxZ7s48ft.png\"/></p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"岭回归\">岭回归<a class=\"anchor-link\" href=\"#岭回归\">¶</a></h3>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p>公式$\\pmb{\\theta}=(\\pmb{x}^T\\pmb{x})^{-1}\\pmb{x}^Ty$不可逆原因:</p>\n",
      "<ul>\n",
      "<li>矩阵可逆的充要条件：满秩；</li>\n",
      "<li>存在噪声维，使得特征间存在线性关系，导致矩阵的秩小于特征维度；</li>\n",
      "<li>特征数比样本还多的时候，方程的个数比未知数的个数还要少，所以会导致矩阵的秩小于样本数,无穷多解满足该情况，进而矩阵不可逆。</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p>为了解决这个问题，岭回归在最小二乘估计的基础上增加了一项，即岭回归估计：\n",
      "$$\\pmb{\\theta}=(\\pmb{x}^T\\pmb{x}+\\lambda\\pmb{I})^{-1}\\pmb{x}^Ty$$</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p>而岭回归模型的目标函数在线性模型的基础上加了L2范数的惩罚项：\n",
      "$$Loss=\\frac{1}{2N}\\sum_{i=1}^N(y^{(i)}-f(\\pmb{x}^{(i)},\\pmb{\\theta}))^2+\\lambda \\sum_{j=0}^N\\theta_j^2$$\n",
      "当岭参数$\\lambda$时，得到最小二乘解，当岭参数$\\lambda$趋向更大时，岭回归系数 $\\pmb{\\theta}$ 估计趋向于0。\n",
      "从岭回归的原理可以知道，岭回归就是改良后的最小二乘估计法，通过放弃最小二乘法的无偏性，通过损失部分特征信息，降低模型精度来得到更符合实际情况的回归系数。</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"winequality-white数据集\">winequality-white数据集<a class=\"anchor-link\" href=\"#winequality-white数据集\">¶</a></h3>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing code_cell rendered\">\n",
      "<div class=\"input\">\n",
      "<div class=\"prompt input_prompt\">In [8]:</div>\n",
      "<div class=\"inner_cell\">\n",
      "<div class=\"input_area\">\n",
      "<div class=\"highlight hl-ipython3\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">pandas</span> <span class=\"k\">as</span> <span class=\"nn\">pd</span>\n",
      "<span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
      "<span class=\"n\">data</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">read_csv</span><span class=\"p\">(</span><span class=\"s2\">\"winequality-white.csv\"</span><span class=\"p\">)</span>\n",
      "<span class=\"n\">data</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"output_wrapper\">\n",
      "<div class=\"output\">\n",
      "<div class=\"output_area\">\n",
      "<div class=\"prompt output_prompt\">Out[8]:</div>\n",
      "<div class=\"output_html rendered_html output_subarea output_execute_result\">\n",
      "<div>\n",
      "<style scoped=\"\">\n",
      "    .dataframe tbody tr th:only-of-type {\n",
      "        vertical-align: middle;\n",
      "    }\n",
      "\n",
      "    .dataframe tbody tr th {\n",
      "        vertical-align: top;\n",
      "    }\n",
      "\n",
      "    .dataframe thead th {\n",
      "        text-align: right;\n",
      "    }\n",
      "</style>\n",
      "<table border=\"1\" class=\"dataframe\">\n",
      "<thead>\n",
      "<tr style=\"text-align: right;\">\n",
      "<th></th>\n",
      "<th>fixed acidity</th>\n",
      "<th>volatile acidity</th>\n",
      "<th>citric acid</th>\n",
      "<th>residual sugar</th>\n",
      "<th>chlorides</th>\n",
      "<th>free sulfur dioxide</th>\n",
      "<th>total sulfur dioxide</th>\n",
      "<th>density</th>\n",
      "<th>pH</th>\n",
      "<th>sulphates</th>\n",
      "<th>alcohol</th>\n",
      "<th>quality</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr>\n",
      "<th>0</th>\n",
      "<td>7.0</td>\n",
      "<td>0.27</td>\n",
      "<td>0.36</td>\n",
      "<td>20.7</td>\n",
      "<td>0.045</td>\n",
      "<td>45.0</td>\n",
      "<td>170.0</td>\n",
      "<td>1.00100</td>\n",
      "<td>3.00</td>\n",
      "<td>0.45</td>\n",
      "<td>8.8</td>\n",
      "<td>6</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>1</th>\n",
      "<td>6.3</td>\n",
      "<td>0.30</td>\n",
      "<td>0.34</td>\n",
      "<td>1.6</td>\n",
      "<td>0.049</td>\n",
      "<td>14.0</td>\n",
      "<td>132.0</td>\n",
      "<td>0.99400</td>\n",
      "<td>3.30</td>\n",
      "<td>0.49</td>\n",
      "<td>9.5</td>\n",
      "<td>6</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>2</th>\n",
      "<td>8.1</td>\n",
      "<td>0.28</td>\n",
      "<td>0.40</td>\n",
      "<td>6.9</td>\n",
      "<td>0.050</td>\n",
      "<td>30.0</td>\n",
      "<td>97.0</td>\n",
      "<td>0.99510</td>\n",
      "<td>3.26</td>\n",
      "<td>0.44</td>\n",
      "<td>10.1</td>\n",
      "<td>6</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>3</th>\n",
      "<td>7.2</td>\n",
      "<td>0.23</td>\n",
      "<td>0.32</td>\n",
      "<td>8.5</td>\n",
      "<td>0.058</td>\n",
      "<td>47.0</td>\n",
      "<td>186.0</td>\n",
      "<td>0.99560</td>\n",
      "<td>3.19</td>\n",
      "<td>0.40</td>\n",
      "<td>9.9</td>\n",
      "<td>6</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4</th>\n",
      "<td>7.2</td>\n",
      "<td>0.23</td>\n",
      "<td>0.32</td>\n",
      "<td>8.5</td>\n",
      "<td>0.058</td>\n",
      "<td>47.0</td>\n",
      "<td>186.0</td>\n",
      "<td>0.99560</td>\n",
      "<td>3.19</td>\n",
      "<td>0.40</td>\n",
      "<td>9.9</td>\n",
      "<td>6</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>...</th>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4893</th>\n",
      "<td>6.2</td>\n",
      "<td>0.21</td>\n",
      "<td>0.29</td>\n",
      "<td>1.6</td>\n",
      "<td>0.039</td>\n",
      "<td>24.0</td>\n",
      "<td>92.0</td>\n",
      "<td>0.99114</td>\n",
      "<td>3.27</td>\n",
      "<td>0.50</td>\n",
      "<td>11.2</td>\n",
      "<td>6</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4894</th>\n",
      "<td>6.6</td>\n",
      "<td>0.32</td>\n",
      "<td>0.36</td>\n",
      "<td>8.0</td>\n",
      "<td>0.047</td>\n",
      "<td>57.0</td>\n",
      "<td>168.0</td>\n",
      "<td>0.99490</td>\n",
      "<td>3.15</td>\n",
      "<td>0.46</td>\n",
      "<td>9.6</td>\n",
      "<td>5</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4895</th>\n",
      "<td>6.5</td>\n",
      "<td>0.24</td>\n",
      "<td>0.19</td>\n",
      "<td>1.2</td>\n",
      "<td>0.041</td>\n",
      "<td>30.0</td>\n",
      "<td>111.0</td>\n",
      "<td>0.99254</td>\n",
      "<td>2.99</td>\n",
      "<td>0.46</td>\n",
      "<td>9.4</td>\n",
      "<td>6</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4896</th>\n",
      "<td>5.5</td>\n",
      "<td>0.29</td>\n",
      "<td>0.30</td>\n",
      "<td>1.1</td>\n",
      "<td>0.022</td>\n",
      "<td>20.0</td>\n",
      "<td>110.0</td>\n",
      "<td>0.98869</td>\n",
      "<td>3.34</td>\n",
      "<td>0.38</td>\n",
      "<td>12.8</td>\n",
      "<td>7</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4897</th>\n",
      "<td>6.0</td>\n",
      "<td>0.21</td>\n",
      "<td>0.38</td>\n",
      "<td>0.8</td>\n",
      "<td>0.020</td>\n",
      "<td>22.0</td>\n",
      "<td>98.0</td>\n",
      "<td>0.98941</td>\n",
      "<td>3.26</td>\n",
      "<td>0.32</td>\n",
      "<td>11.8</td>\n",
      "<td>6</td>\n",
      "</tr>\n",
      "</tbody>\n",
      "</table>\n",
      "<p>4898 rows × 12 columns</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p>最后一列是质量的评级，前面其他的都是酒的特征</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<h3 id=\"对数据集进行预处理\">对数据集进行预处理<a class=\"anchor-link\" href=\"#对数据集进行预处理\">¶</a></h3><p>对数据集的预处理是一个十分重要的步骤，能够使不同量纲的特征处于同一数值量级，减少方差大的特征的影响，使模型更准确，并加快学习算法的收敛速度。</p>\n",
      "<p>常用的预处理方法有：标准化、归一化和中心化。同学们根据需要从中选择一种或几种方法进行预处理（采用其他方法亦可）。</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
      "</div><div class=\"inner_cell\">\n",
      "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
      "<p><img alt=\"image.png\" src=\"https://s2.loli.net/2022/10/04/WqxB76cXLGtePSK.png\"/></p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing code_cell rendered\">\n",
      "<div class=\"input\">\n",
      "<div class=\"prompt input_prompt\">In [2]:</div>\n",
      "<div class=\"inner_cell\">\n",
      "<div class=\"input_area\">\n",
      "<div class=\"highlight hl-ipython3\"><pre><span></span><span class=\"c1\"># 中心化代码</span>\n",
      "<span class=\"k\">def</span> <span class=\"nf\">Normalization_fun</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">):</span>\n",
      "    <span class=\"c1\"># 特征零均值</span>\n",
      "    <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">-</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">))</span> <span class=\"o\">/</span> <span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">min</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">))</span>\n",
      "    <span class=\"k\">return</span> <span class=\"n\">x</span>\n",
      "\n",
      "<span class=\"c1\"># 提取特征和标签</span>\n",
      "<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[:,</span> <span class=\"mi\">0</span><span class=\"p\">:</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>  <span class=\"c1\"># N D</span>\n",
      "<span class=\"n\">X</span> <span class=\"o\">=</span> <span class=\"n\">Normalization_fun</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">)</span>\n",
      "<span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">iloc</span><span class=\"p\">[:,</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing code_cell rendered\">\n",
      "<div class=\"input\">\n",
      "<div class=\"prompt input_prompt\">In [7]:</div>\n",
      "<div class=\"inner_cell\">\n",
      "<div class=\"input_area\">\n",
      "<div class=\"highlight hl-ipython3\"><pre><span></span><span class=\"c1\"># 可视化中心化后的sulphates特征</span>\n",
      "<span class=\"kn\">import</span> <span class=\"nn\">matplotlib.pyplot</span> <span class=\"k\">as</span> <span class=\"nn\">plt</span>\n",
      "<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">hist</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"p\">[</span><span class=\"s2\">\"sulphates\"</span><span class=\"p\">])</span>\n",
      "<span class=\"n\">plt</span><span class=\"o\">.</span><span class=\"n\">show</span><span class=\"p\">()</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"output_wrapper\">\n",
      "<div class=\"output\">\n",
      "<div class=\"output_area\">\n",
      "<div class=\"prompt\"></div>\n",
      "<div class=\"output_png output_subarea\">\n",
      "<img src=\"data:image/png;base64,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\n",
      "\"/>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing code_cell rendered\">\n",
      "<div class=\"input\">\n",
      "<div class=\"prompt input_prompt\">In [4]:</div>\n",
      "<div class=\"inner_cell\">\n",
      "<div class=\"input_area\">\n",
      "<div class=\"highlight hl-ipython3\"><pre><span></span><span class=\"c1\"># 这里注意一个小trick：回归系数会比特征x多一维，为了向量相乘方便，可以在训练集X左侧添加全为1的一列</span>\n",
      "<span class=\"n\">data0</span> <span class=\"o\">=</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">concat</span><span class=\"p\">([</span><span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">ones</span><span class=\"p\">(</span><span class=\"n\">X</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]),</span> <span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'x0'</span><span class=\"p\">]),</span> <span class=\"n\">X</span><span class=\"p\">],</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n",
      "<span class=\"n\">data0</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"output_wrapper\">\n",
      "<div class=\"output\">\n",
      "<div class=\"output_area\">\n",
      "<div class=\"prompt output_prompt\">Out[4]:</div>\n",
      "<div class=\"output_html rendered_html output_subarea output_execute_result\">\n",
      "<div>\n",
      "<style scoped=\"\">\n",
      "    .dataframe tbody tr th:only-of-type {\n",
      "        vertical-align: middle;\n",
      "    }\n",
      "\n",
      "    .dataframe tbody tr th {\n",
      "        vertical-align: top;\n",
      "    }\n",
      "\n",
      "    .dataframe thead th {\n",
      "        text-align: right;\n",
      "    }\n",
      "</style>\n",
      "<table border=\"1\" class=\"dataframe\">\n",
      "<thead>\n",
      "<tr style=\"text-align: right;\">\n",
      "<th></th>\n",
      "<th>x0</th>\n",
      "<th>fixed acidity</th>\n",
      "<th>volatile acidity</th>\n",
      "<th>citric acid</th>\n",
      "<th>residual sugar</th>\n",
      "<th>chlorides</th>\n",
      "<th>free sulfur dioxide</th>\n",
      "<th>total sulfur dioxide</th>\n",
      "<th>density</th>\n",
      "<th>pH</th>\n",
      "<th>sulphates</th>\n",
      "<th>alcohol</th>\n",
      "</tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr>\n",
      "<th>0</th>\n",
      "<td>1.0</td>\n",
      "<td>0.013963</td>\n",
      "<td>-0.008080</td>\n",
      "<td>0.015547</td>\n",
      "<td>0.219457</td>\n",
      "<td>-0.002292</td>\n",
      "<td>0.033770</td>\n",
      "<td>0.073409</td>\n",
      "<td>0.134425</td>\n",
      "<td>-0.171151</td>\n",
      "<td>-0.046334</td>\n",
      "<td>-0.276495</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>1</th>\n",
      "<td>1.0</td>\n",
      "<td>-0.053345</td>\n",
      "<td>0.021332</td>\n",
      "<td>0.003499</td>\n",
      "<td>-0.073488</td>\n",
      "<td>0.009578</td>\n",
      "<td>-0.074244</td>\n",
      "<td>-0.014758</td>\n",
      "<td>-0.000528</td>\n",
      "<td>0.101576</td>\n",
      "<td>0.000178</td>\n",
      "<td>-0.163591</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>2</th>\n",
      "<td>1.0</td>\n",
      "<td>0.119732</td>\n",
      "<td>0.001724</td>\n",
      "<td>0.039644</td>\n",
      "<td>0.007800</td>\n",
      "<td>0.012545</td>\n",
      "<td>-0.018495</td>\n",
      "<td>-0.095964</td>\n",
      "<td>0.020679</td>\n",
      "<td>0.065212</td>\n",
      "<td>-0.057961</td>\n",
      "<td>-0.066817</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>3</th>\n",
      "<td>1.0</td>\n",
      "<td>0.033193</td>\n",
      "<td>-0.047295</td>\n",
      "<td>-0.008549</td>\n",
      "<td>0.032340</td>\n",
      "<td>0.036284</td>\n",
      "<td>0.040738</td>\n",
      "<td>0.110532</td>\n",
      "<td>0.030319</td>\n",
      "<td>0.001576</td>\n",
      "<td>-0.104473</td>\n",
      "<td>-0.099075</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4</th>\n",
      "<td>1.0</td>\n",
      "<td>0.033193</td>\n",
      "<td>-0.047295</td>\n",
      "<td>-0.008549</td>\n",
      "<td>0.032340</td>\n",
      "<td>0.036284</td>\n",
      "<td>0.040738</td>\n",
      "<td>0.110532</td>\n",
      "<td>0.030319</td>\n",
      "<td>0.001576</td>\n",
      "<td>-0.104473</td>\n",
      "<td>-0.099075</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>...</th>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4893</th>\n",
      "<td>1.0</td>\n",
      "<td>-0.062960</td>\n",
      "<td>-0.066903</td>\n",
      "<td>-0.026621</td>\n",
      "<td>-0.073488</td>\n",
      "<td>-0.020096</td>\n",
      "<td>-0.039401</td>\n",
      "<td>-0.107565</td>\n",
      "<td>-0.055666</td>\n",
      "<td>0.074303</td>\n",
      "<td>0.011806</td>\n",
      "<td>0.110602</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4894</th>\n",
      "<td>1.0</td>\n",
      "<td>-0.024499</td>\n",
      "<td>0.040940</td>\n",
      "<td>0.015547</td>\n",
      "<td>0.024672</td>\n",
      "<td>0.003643</td>\n",
      "<td>0.075582</td>\n",
      "<td>0.068769</td>\n",
      "<td>0.016823</td>\n",
      "<td>-0.034788</td>\n",
      "<td>-0.034706</td>\n",
      "<td>-0.147462</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4895</th>\n",
      "<td>1.0</td>\n",
      "<td>-0.034114</td>\n",
      "<td>-0.037491</td>\n",
      "<td>-0.086862</td>\n",
      "<td>-0.079623</td>\n",
      "<td>-0.014161</td>\n",
      "<td>-0.018495</td>\n",
      "<td>-0.063482</td>\n",
      "<td>-0.028675</td>\n",
      "<td>-0.180242</td>\n",
      "<td>-0.034706</td>\n",
      "<td>-0.179720</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4896</th>\n",
      "<td>1.0</td>\n",
      "<td>-0.130268</td>\n",
      "<td>0.011528</td>\n",
      "<td>-0.020597</td>\n",
      "<td>-0.081157</td>\n",
      "<td>-0.070541</td>\n",
      "<td>-0.053338</td>\n",
      "<td>-0.065802</td>\n",
      "<td>-0.102899</td>\n",
      "<td>0.137939</td>\n",
      "<td>-0.127729</td>\n",
      "<td>0.368667</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<th>4897</th>\n",
      "<td>1.0</td>\n",
      "<td>-0.082191</td>\n",
      "<td>-0.066903</td>\n",
      "<td>0.027595</td>\n",
      "<td>-0.085758</td>\n",
      "<td>-0.076476</td>\n",
      "<td>-0.046370</td>\n",
      "<td>-0.093644</td>\n",
      "<td>-0.089018</td>\n",
      "<td>0.065212</td>\n",
      "<td>-0.197496</td>\n",
      "<td>0.207376</td>\n",
      "</tr>\n",
      "</tbody>\n",
      "</table>\n",
      "<p>4898 rows × 12 columns</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing code_cell rendered\">\n",
      "<div class=\"input\">\n",
      "<div class=\"prompt input_prompt\">In [5]:</div>\n",
      "<div class=\"inner_cell\">\n",
      "<div class=\"input_area\">\n",
      "<div class=\"highlight hl-ipython3\"><pre><span></span><span class=\"c1\"># 初始化回归系数</span>\n",
      "<span class=\"n\">W_init</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randn</span><span class=\"p\">(</span><span class=\"n\">data0</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">1</span><span class=\"p\">],</span> <span class=\"mi\">1</span><span class=\"p\">)</span>\n",
      "<span class=\"n\">W_init</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"output_wrapper\">\n",
      "<div class=\"output\">\n",
      "<div class=\"output_area\">\n",
      "<div class=\"prompt output_prompt\">Out[5]:</div>\n",
      "<div class=\"output_text output_subarea output_execute_result\">\n",
      "<pre>array([[-1.0794487 ],\n",
      "       [ 1.05050362],\n",
      "       [-0.45591875],\n",
      "       [-1.1072212 ],\n",
      "       [ 1.24852415],\n",
      "       [ 0.23413631],\n",
      "       [-0.15884593],\n",
      "       [-0.55216419],\n",
      "       [-0.90922601],\n",
      "       [ 1.17422972],\n",
      "       [-0.83248232],\n",
      "       [-0.3835054 ]])</pre>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"cell border-box-sizing code_cell rendered\">\n",
      "<div class=\"input\">\n",
      "<div class=\"prompt input_prompt\">In [6]:</div>\n",
      "<div class=\"inner_cell\">\n",
      "<div class=\"input_area\">\n",
      "<div class=\"highlight hl-ipython3\"><pre><span></span><span class=\"c1\">## TODO：批量梯度下降</span>\n",
      "<span class=\"c1\">## TODO：随机梯度下降</span>\n",
      "<span class=\"c1\">## TODO：回归模型在机器学习和统计学上的差异</span>\n",
      "<span class=\"c1\">## TODO：岭回归</span>\n",
      "</pre></div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18006"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "#  for local html file\n",
    "response = open(\"实验二：回归模型.html\",encoding='utf8')\n",
    "text = response.read()\n",
    "\n",
    "soup = BeautifulSoup(text, 'lxml')\n",
    "# see some of the html\n",
    "print(soup.div)\n",
    "dictionary = {'nbformat': 4, 'nbformat_minor': 1, 'cells': [], 'metadata': {}}\n",
    "for d in soup.findAll(\"div\"):\n",
    "    if 'class' in d.attrs.keys():\n",
    "        for clas in d.attrs[\"class\"]:\n",
    "            if clas in [\"text_cell_render\",\"input_area\"]:\n",
    "                # code cell\n",
    "                if clas ==\"input_area\":\n",
    "                    cell = {}\n",
    "                    cell['metadata'] = {}\n",
    "                    cell['outputs'] = []\n",
    "                    cell['source'] = [d.get_text()]\n",
    "                    cell['execution_count'] = None\n",
    "                    cell['cell_type'] = 'code'\n",
    "                    dictionary['cells'].append(cell)\n",
    "\n",
    "                else:\n",
    "                    cell = {}\n",
    "                    cell['metadata'] = {}\n",
    "\n",
    "                    cell['source'] = [d.decode_contents()]\n",
    "                    cell['cell_type'] = 'markdown'\n",
    "                    dictionary['cells'].append(cell)\n",
    "open('notebook.ipynb', 'w').write(json.dumps(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8e1ea876934806d5ee93b7d75cbcef8afd78554b278b3a200735f8e6fd5446f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
